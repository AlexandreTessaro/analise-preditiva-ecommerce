{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸ¯ DemonstraÃ§Ã£o PrÃ¡tica - AnÃ¡lise Preditiva E-commerce\n",
        "\n",
        "## Sistema de RecomendaÃ§Ã£o de Produtos com MongoDB + PostgreSQL\n",
        "\n",
        "Este notebook demonstra uma aplicaÃ§Ã£o prÃ¡tica de anÃ¡lise preditiva para um sistema de recomendaÃ§Ã£o de produtos e-commerce, utilizando uma arquitetura hÃ­brida com MongoDB e PostgreSQL.\n",
        "\n",
        "### ğŸ“‹ Objetivos da DemonstraÃ§Ã£o:\n",
        "- **AnÃ¡lise Descritiva:** Entender o comportamento dos usuÃ¡rios e produtos\n",
        "- **AnÃ¡lise Preditiva:** Predizer probabilidade de compra e churn\n",
        "- **Clustering:** Segmentar usuÃ¡rios por comportamento\n",
        "- **RecomendaÃ§Ãµes:** Gerar recomendaÃ§Ãµes personalizadas\n",
        "- **VisualizaÃ§Ãµes:** Criar dashboards interativos\n",
        "\n",
        "### ğŸ› ï¸ Tecnologias Utilizadas:\n",
        "- **MongoDB:** Dados nÃ£o estruturados e comportamento\n",
        "- **PostgreSQL:** Dados transacionais e relatÃ³rios\n",
        "- **Python:** AnÃ¡lise de dados e machine learning\n",
        "- **Scikit-learn:** Algoritmos de ML\n",
        "- **Matplotlib/Seaborn:** VisualizaÃ§Ãµes\n",
        "- **Pandas:** ManipulaÃ§Ã£o de dados\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ“¦ Importar Bibliotecas NecessÃ¡rias\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta\n",
        "import random\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Machine Learning\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Bancos de dados\n",
        "from pymongo import MongoClient\n",
        "import psycopg2\n",
        "from psycopg2.extras import RealDictCursor\n",
        "\n",
        "# ConfiguraÃ§Ãµes de visualizaÃ§Ã£o\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "\n",
        "print(\"âœ… Bibliotecas importadas com sucesso!\")\n",
        "print(\"ğŸš€ Pronto para iniciar a demonstraÃ§Ã£o!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ—„ï¸ Parte 1: ConexÃ£o com Bancos de Dados\n",
        "\n",
        "### MongoDB - Dados NÃ£o Estruturados\n",
        "MongoDB serÃ¡ usado para armazenar:\n",
        "- **Produtos:** CaracterÃ­sticas flexÃ­veis e reviews\n",
        "- **Comportamento:** Eventos de navegaÃ§Ã£o e interaÃ§Ã£o\n",
        "- **RecomendaÃ§Ãµes:** Scores e matrizes de similaridade\n",
        "\n",
        "### PostgreSQL - Dados Transacionais\n",
        "PostgreSQL serÃ¡ usado para:\n",
        "- **UsuÃ¡rios:** Dados pessoais e segmentaÃ§Ã£o\n",
        "- **Pedidos:** TransaÃ§Ãµes e histÃ³rico de compras\n",
        "- **RelatÃ³rios:** AnÃ¡lises estruturadas e KPIs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ”Œ Conectar ao MongoDB\n",
        "try:\n",
        "    mongo_client = MongoClient('mongodb://localhost:27017')\n",
        "    mongo_db = mongo_client['ecommerce_demo']\n",
        "    print(\"âœ… Conectado ao MongoDB com sucesso!\")\n",
        "    \n",
        "    # Testar conexÃ£o\n",
        "    mongo_db.command('ping')\n",
        "    print(\"âœ… Ping MongoDB: OK\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"âŒ Erro ao conectar MongoDB: {e}\")\n",
        "    print(\"ğŸ’¡ Certifique-se de que o MongoDB estÃ¡ rodando\")\n",
        "    mongo_client = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ”Œ Conectar ao PostgreSQL\n",
        "try:\n",
        "    postgres_conn = psycopg2.connect(\n",
        "        host='localhost',\n",
        "        database='ecommerce_demo',\n",
        "        user='postgres',\n",
        "        password='postgres'\n",
        "    )\n",
        "    postgres_cursor = postgres_conn.cursor(cursor_factory=RealDictCursor)\n",
        "    print(\"âœ… Conectado ao PostgreSQL com sucesso!\")\n",
        "    \n",
        "    # Testar conexÃ£o\n",
        "    postgres_cursor.execute(\"SELECT version();\")\n",
        "    version = postgres_cursor.fetchone()\n",
        "    print(f\"âœ… PostgreSQL Version: {version[0][:50]}...\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"âŒ Erro ao conectar PostgreSQL: {e}\")\n",
        "    print(\"ğŸ’¡ Certifique-se de que o PostgreSQL estÃ¡ rodando e o banco existe\")\n",
        "    postgres_conn = None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“Š Parte 2: AnÃ¡lise Descritiva - MongoDB\n",
        "\n",
        "### Objetivo: Entender o comportamento dos usuÃ¡rios atravÃ©s de dados nÃ£o estruturados\n",
        "\n",
        "Vamos analisar:\n",
        "1. **Produtos mais visualizados**\n",
        "2. **PadrÃµes de navegaÃ§Ã£o**\n",
        "3. **Eventos de conversÃ£o**\n",
        "4. **SegmentaÃ§Ã£o por comportamento**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ“Š AnÃ¡lise de Comportamento - MongoDB\n",
        "if mongo_client:\n",
        "    print(\"ğŸ” Analisando comportamento dos usuÃ¡rios...\")\n",
        "    \n",
        "    # Pipeline para anÃ¡lise de comportamento\n",
        "    pipeline = [\n",
        "        {\"$unwind\": \"$eventos\"},\n",
        "        {\"$group\": {\n",
        "            \"_id\": \"$usuario_id\",\n",
        "            \"total_eventos\": {\"$sum\": 1},\n",
        "            \"page_views\": {\n",
        "                \"$sum\": {\"$cond\": [{\"$eq\": [\"$eventos.tipo\", \"page_view\"]}, 1, 0]}\n",
        "            },\n",
        "            \"clicks\": {\n",
        "                \"$sum\": {\"$cond\": [{\"$eq\": [\"$eventos.tipo\", \"click\"]}, 1, 0]}\n",
        "            },\n",
        "            \"add_to_cart\": {\n",
        "                \"$sum\": {\"$cond\": [{\"$eq\": [\"$eventos.tipo\", \"add_to_cart\"]}, 1, 0]}\n",
        "            },\n",
        "            \"searches\": {\n",
        "                \"$sum\": {\"$cond\": [{\"$eq\": [\"$eventos.tipo\", \"search\"]}, 1, 0]}\n",
        "            },\n",
        "            \"tempo_total\": {\"$sum\": \"$eventos.tempo_pagina\"},\n",
        "            \"produtos_unicos\": {\"$addToSet\": \"$eventos.produto_id\"}\n",
        "        }},\n",
        "        {\"$project\": {\n",
        "            \"usuario_id\": \"$_id\",\n",
        "            \"total_eventos\": 1,\n",
        "            \"page_views\": 1,\n",
        "            \"clicks\": 1,\n",
        "            \"add_to_cart\": 1,\n",
        "            \"searches\": 1,\n",
        "            \"tempo_total\": 1,\n",
        "            \"produtos_unicos\": {\"$size\": \"$produtos_unicos\"},\n",
        "            \"taxa_conversao\": {\n",
        "                \"$cond\": [\n",
        "                    {\"$gt\": [\"$page_views\", 0]},\n",
        "                    {\"$divide\": [\"$add_to_cart\", \"$page_views\"]},\n",
        "                    0\n",
        "                ]\n",
        "            },\n",
        "            \"tempo_medio_evento\": {\n",
        "                \"$cond\": [\n",
        "                    {\"$gt\": [\"$total_eventos\", 0]},\n",
        "                    {\"$divide\": [\"$tempo_total\", \"$total_eventos\"]},\n",
        "                    0\n",
        "                ]\n",
        "            }\n",
        "        }},\n",
        "        {\"$sort\": {\"total_eventos\": -1}}\n",
        "    ]\n",
        "    \n",
        "    # Executar pipeline\n",
        "    comportamento_data = list(mongo_db.usuarios_comportamento.aggregate(pipeline))\n",
        "    \n",
        "    if comportamento_data:\n",
        "        comportamento_df = pd.DataFrame(comportamento_data)\n",
        "        print(f\"âœ… Analisados {len(comportamento_df)} usuÃ¡rios\")\n",
        "        print(\"\\nğŸ“ˆ Resumo do Comportamento:\")\n",
        "        print(comportamento_df.describe().round(2))\n",
        "        \n",
        "        # Mostrar top usuÃ¡rios mais ativos\n",
        "        print(\"\\nğŸ† Top 5 UsuÃ¡rios Mais Ativos:\")\n",
        "        top_usuarios = comportamento_df.head()\n",
        "        for _, user in top_usuarios.iterrows():\n",
        "            print(f\"  {user['usuario_id']}: {user['total_eventos']} eventos, \"\n",
        "                  f\"{user['taxa_conversao']:.1%} conversÃ£o\")\n",
        "    else:\n",
        "        print(\"âŒ Nenhum dado de comportamento encontrado\")\n",
        "        comportamento_df = None\n",
        "else:\n",
        "    print(\"âŒ MongoDB nÃ£o disponÃ­vel - usando dados simulados\")\n",
        "    # Criar dados simulados para demonstraÃ§Ã£o\n",
        "    np.random.seed(42)\n",
        "    comportamento_df = pd.DataFrame({\n",
        "        'usuario_id': [f'U{i:03d}' for i in range(1, 21)],\n",
        "        'total_eventos': np.random.poisson(15, 20),\n",
        "        'page_views': np.random.poisson(10, 20),\n",
        "        'clicks': np.random.poisson(8, 20),\n",
        "        'add_to_cart': np.random.poisson(2, 20),\n",
        "        'searches': np.random.poisson(3, 20),\n",
        "        'produtos_unicos': np.random.randint(1, 8, 20),\n",
        "        'taxa_conversao': np.random.beta(2, 8, 20),\n",
        "        'tempo_medio_evento': np.random.normal(45, 15, 20)\n",
        "    })\n",
        "    print(f\"âœ… Criados {len(comportamento_df)} usuÃ¡rios simulados\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¯ Parte 3: AnÃ¡lise Preditiva - Clustering de UsuÃ¡rios\n",
        "\n",
        "### Objetivo: Segmentar usuÃ¡rios por comportamento usando K-Means\n",
        "\n",
        "Vamos identificar:\n",
        "1. **UsuÃ¡rios Ativos e Convertidos** ğŸ”¥\n",
        "2. **UsuÃ¡rios Ativos mas Baixa ConversÃ£o** ğŸ‘€  \n",
        "3. **UsuÃ¡rios Passivos** ğŸ˜´\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ¯ Clustering de UsuÃ¡rios com K-Means\n",
        "if comportamento_df is not None and not comportamento_df.empty:\n",
        "    print(\"ğŸ” Aplicando clustering K-Means...\")\n",
        "    \n",
        "    # Preparar features para clustering\n",
        "    features = ['total_eventos', 'page_views', 'clicks', 'add_to_cart', 'produtos_unicos', 'taxa_conversao']\n",
        "    X = comportamento_df[features].fillna(0)\n",
        "    \n",
        "    # Normalizar dados\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "    \n",
        "    # Aplicar K-Means\n",
        "    kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
        "    comportamento_df['cluster'] = kmeans.fit_predict(X_scaled)\n",
        "    \n",
        "    # AnÃ¡lise dos clusters\n",
        "    cluster_analysis = comportamento_df.groupby('cluster')[features].mean()\n",
        "    \n",
        "    print(\"ğŸ“Š AnÃ¡lise de Clusters:\")\n",
        "    print(cluster_analysis.round(2))\n",
        "    \n",
        "    # Interpretar clusters\n",
        "    print(\"\\nğŸ·ï¸ InterpretaÃ§Ã£o dos Clusters:\")\n",
        "    cluster_names = {\n",
        "        0: \"ğŸ˜´ UsuÃ¡rios Passivos\",\n",
        "        1: \"ğŸ‘€ UsuÃ¡rios Ativos mas Baixa ConversÃ£o\", \n",
        "        2: \"ğŸ”¥ UsuÃ¡rios Ativos e Convertidos\"\n",
        "    }\n",
        "    \n",
        "    for cluster_id in range(3):\n",
        "        cluster_data = comportamento_df[comportamento_df['cluster'] == cluster_id]\n",
        "        avg_events = cluster_data['total_eventos'].mean()\n",
        "        avg_conversion = cluster_data['taxa_conversao'].mean()\n",
        "        \n",
        "        print(f\"\\n{cluster_names[cluster_id]}:\")\n",
        "        print(f\"  UsuÃ¡rios: {len(cluster_data)}\")\n",
        "        print(f\"  Eventos mÃ©dios: {avg_events:.1f}\")\n",
        "        print(f\"  Taxa conversÃ£o: {avg_conversion:.1%}\")\n",
        "        print(f\"  Produtos Ãºnicos: {cluster_data['produtos_unicos'].mean():.1f}\")\n",
        "        \n",
        "        # Mostrar alguns usuÃ¡rios do cluster\n",
        "        sample_users = cluster_data['usuario_id'].head(3).tolist()\n",
        "        print(f\"  Exemplos: {', '.join(sample_users)}\")\n",
        "    \n",
        "    print(f\"\\nâœ… Clustering concluÃ­do! {len(comportamento_df)} usuÃ¡rios segmentados em 3 grupos\")\n",
        "else:\n",
        "    print(\"âŒ Dados de comportamento nÃ£o disponÃ­veis para clustering\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“ˆ Parte 4: AnÃ¡lise Preditiva - PostgreSQL\n",
        "\n",
        "### Objetivo: Predizer churn de usuÃ¡rios baseado em dados transacionais\n",
        "\n",
        "Vamos analisar:\n",
        "1. **HistÃ³rico de compras**\n",
        "2. **PadrÃµes de gastos**\n",
        "3. **FrequÃªncia de compras**\n",
        "4. **Probabilidade de churn**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ“ˆ AnÃ¡lise Preditiva - PostgreSQL\n",
        "if postgres_conn:\n",
        "    print(\"ğŸ” Analisando dados transacionais...\")\n",
        "    \n",
        "    # Query para anÃ¡lise de usuÃ¡rios\n",
        "    query = \"\"\"\n",
        "        SELECT \n",
        "            u.usuario_id,\n",
        "            u.nome,\n",
        "            u.segmento,\n",
        "            u.valor_total_compras,\n",
        "            COUNT(p.id) as total_pedidos,\n",
        "            AVG(p.valor_total) as ticket_medio,\n",
        "            COUNT(DISTINCT ip.produto_id) as produtos_unicos,\n",
        "            MAX(p.data_pedido) as ultima_compra,\n",
        "            EXTRACT(DAYS FROM NOW() - MAX(p.data_pedido)) as dias_sem_comprar,\n",
        "            COUNT(CASE WHEN p.status = 'concluido' THEN 1 END) as pedidos_concluidos,\n",
        "            COUNT(CASE WHEN p.status = 'pendente' THEN 1 END) as pedidos_pendentes,\n",
        "            STDDEV(p.valor_total) as variabilidade_gastos\n",
        "        FROM usuarios u\n",
        "        LEFT JOIN pedidos p ON u.id = p.usuario_id\n",
        "        LEFT JOIN itens_pedido ip ON p.id = ip.pedido_id\n",
        "        GROUP BY u.usuario_id, u.nome, u.segmento, u.valor_total_compras\n",
        "        ORDER BY u.valor_total_compras DESC\n",
        "    \"\"\"\n",
        "    \n",
        "    postgres_cursor.execute(query)\n",
        "    usuarios_transacionais = pd.DataFrame(postgres_cursor.fetchall())\n",
        "    \n",
        "    if not usuarios_transacionais.empty:\n",
        "        print(f\"âœ… Analisados {len(usuarios_transacionais)} usuÃ¡rios transacionais\")\n",
        "        \n",
        "        # Preparar dados para prediÃ§Ã£o de churn\n",
        "        usuarios_transacionais['dias_sem_comprar'] = usuarios_transacionais['dias_sem_comprar'].fillna(365)\n",
        "        usuarios_transacionais['ticket_medio'] = usuarios_transacionais['ticket_medio'].fillna(0)\n",
        "        usuarios_transacionais['produtos_unicos'] = usuarios_transacionais['produtos_unicos'].fillna(0)\n",
        "        usuarios_transacionais['variabilidade_gastos'] = usuarios_transacionais['variabilidade_gastos'].fillna(0)\n",
        "        \n",
        "        # Criar variÃ¡vel target (churn = dias sem comprar > 30)\n",
        "        usuarios_transacionais['churn'] = (usuarios_transacionais['dias_sem_comprar'] > 30).astype(int)\n",
        "        \n",
        "        print(\"\\nğŸ“Š EstatÃ­sticas dos UsuÃ¡rios:\")\n",
        "        print(f\"  Valor mÃ©dio de compras: R$ {usuarios_transacionais['valor_total_compras'].mean():,.2f}\")\n",
        "        print(f\"  Pedidos mÃ©dios por usuÃ¡rio: {usuarios_transacionais['total_pedidos'].mean():.1f}\")\n",
        "        print(f\"  Ticket mÃ©dio: R$ {usuarios_transacionais['ticket_medio'].mean():,.2f}\")\n",
        "        print(f\"  Taxa de churn: {usuarios_transacionais['churn'].mean():.1%}\")\n",
        "        \n",
        "        # Mostrar usuÃ¡rios com maior risco de churn\n",
        "        risco_churn = usuarios_transacionais[usuarios_transacionais['churn'] == 1].sort_values('dias_sem_comprar', ascending=False)\n",
        "        print(f\"\\nâš ï¸ UsuÃ¡rios com Risco de Churn ({len(risco_churn)} usuÃ¡rios):\")\n",
        "        for _, user in risco_churn.head(5).iterrows():\n",
        "            print(f\"  {user['nome']}: {user['dias_sem_comprar']:.0f} dias sem comprar, \"\n",
        "                  f\"R$ {user['valor_total_compras']:,.2f} histÃ³rico\")\n",
        "        \n",
        "    else:\n",
        "        print(\"âŒ Nenhum dado transacional encontrado\")\n",
        "        usuarios_transacionais = None\n",
        "else:\n",
        "    print(\"âŒ PostgreSQL nÃ£o disponÃ­vel - usando dados simulados\")\n",
        "    # Criar dados simulados para demonstraÃ§Ã£o\n",
        "    np.random.seed(42)\n",
        "    usuarios_transacionais = pd.DataFrame({\n",
        "        'usuario_id': [f'U{i:03d}' for i in range(1, 21)],\n",
        "        'nome': [f'UsuÃ¡rio {i}' for i in range(1, 21)],\n",
        "        'segmento': np.random.choice(['high_value', 'medium_value', 'low_value', 'new_user'], 20),\n",
        "        'valor_total_compras': np.random.exponential(2000, 20),\n",
        "        'total_pedidos': np.random.poisson(5, 20),\n",
        "        'ticket_medio': np.random.normal(500, 200, 20),\n",
        "        'produtos_unicos': np.random.randint(1, 10, 20),\n",
        "        'dias_sem_comprar': np.random.exponential(30, 20),\n",
        "        'pedidos_concluidos': np.random.poisson(4, 20),\n",
        "        'pedidos_pendentes': np.random.poisson(1, 20),\n",
        "        'variabilidade_gastos': np.random.exponential(100, 20)\n",
        "    })\n",
        "    usuarios_transacionais['churn'] = (usuarios_transacionais['dias_sem_comprar'] > 30).astype(int)\n",
        "    print(f\"âœ… Criados {len(usuarios_transacionais)} usuÃ¡rios transacionais simulados\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ¯ Modelo de PrediÃ§Ã£o de Churn\n",
        "if usuarios_transacionais is not None and not usuarios_transacionais.empty:\n",
        "    print(\"ğŸ¤– Treinando modelo de prediÃ§Ã£o de churn...\")\n",
        "    \n",
        "    # Features para o modelo\n",
        "    features = ['valor_total_compras', 'total_pedidos', 'ticket_medio', 'produtos_unicos', 'dias_sem_comprar', 'variabilidade_gastos']\n",
        "    X = usuarios_transacionais[features].fillna(0)\n",
        "    y = usuarios_transacionais['churn']\n",
        "    \n",
        "    # Dividir dados\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "    \n",
        "    # Treinar modelo Random Forest\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=5)\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    # Fazer prediÃ§Ãµes\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "    \n",
        "    # Avaliar modelo\n",
        "    print(\"ğŸ“ˆ RelatÃ³rio de ClassificaÃ§Ã£o:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    \n",
        "    # ImportÃ¢ncia das features\n",
        "    feature_importance = pd.DataFrame({\n",
        "        'feature': features,\n",
        "        'importance': model.feature_importances_\n",
        "    }).sort_values('importance', ascending=False)\n",
        "    \n",
        "    print(\"\\nğŸ” ImportÃ¢ncia das Features:\")\n",
        "    print(feature_importance.to_string(index=False))\n",
        "    \n",
        "    # PrediÃ§Ãµes para todos os usuÃ¡rios\n",
        "    usuarios_transacionais['probabilidade_churn'] = model.predict_proba(X)[:, 1]\n",
        "    usuarios_transacionais['predicao_churn'] = model.predict(X)\n",
        "    \n",
        "    # Mostrar usuÃ¡rios com maior probabilidade de churn\n",
        "    risco_alto = usuarios_transacionais[usuarios_transacionais['probabilidade_churn'] > 0.7].sort_values('probabilidade_churn', ascending=False)\n",
        "    print(f\"\\nğŸš¨ UsuÃ¡rios com Alto Risco de Churn ({len(risco_alto)} usuÃ¡rios):\")\n",
        "    for _, user in risco_alto.head(5).iterrows():\n",
        "        print(f\"  {user['nome']}: {user['probabilidade_churn']:.1%} probabilidade, \"\n",
        "              f\"{user['dias_sem_comprar']:.0f} dias sem comprar\")\n",
        "    \n",
        "    print(f\"\\nâœ… Modelo treinado com {len(X_train)} amostras de treino e {len(X_test)} de teste\")\n",
        "else:\n",
        "    print(\"âŒ Dados transacionais nÃ£o disponÃ­veis para prediÃ§Ã£o de churn\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“Š Parte 5: VisualizaÃ§Ãµes Interativas\n",
        "\n",
        "### Objetivo: Criar dashboards visuais para anÃ¡lise dos resultados\n",
        "\n",
        "Vamos criar:\n",
        "1. **GrÃ¡ficos de comportamento**\n",
        "2. **AnÃ¡lise de clusters**\n",
        "3. **PrediÃ§Ãµes de churn**\n",
        "4. **ComparaÃ§Ã£o entre bancos**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ“Š Criar VisualizaÃ§Ãµes Interativas\n",
        "print(\"ğŸ¨ Criando visualizaÃ§Ãµes...\")\n",
        "\n",
        "# Configurar figura com subplots\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "fig.suptitle('ğŸ¯ Dashboard - AnÃ¡lise Preditiva E-commerce', fontsize=16, fontweight='bold')\n",
        "\n",
        "# GrÃ¡fico 1: DistribuiÃ§Ã£o de eventos por usuÃ¡rio (MongoDB)\n",
        "if comportamento_df is not None and not comportamento_df.empty:\n",
        "    axes[0, 0].hist(comportamento_df['total_eventos'], bins=15, alpha=0.7, color='skyblue', edgecolor='black')\n",
        "    axes[0, 0].set_title('ğŸ“± DistribuiÃ§Ã£o de Eventos por UsuÃ¡rio', fontweight='bold')\n",
        "    axes[0, 0].set_xlabel('Total de Eventos')\n",
        "    axes[0, 0].set_ylabel('FrequÃªncia')\n",
        "    axes[0, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Adicionar estatÃ­sticas\n",
        "    mean_events = comportamento_df['total_eventos'].mean()\n",
        "    axes[0, 0].axvline(mean_events, color='red', linestyle='--', linewidth=2, label=f'MÃ©dia: {mean_events:.1f}')\n",
        "    axes[0, 0].legend()\n",
        "\n",
        "# GrÃ¡fico 2: Taxa de conversÃ£o vs Page Views\n",
        "if comportamento_df is not None and not comportamento_df.empty:\n",
        "    scatter = axes[0, 1].scatter(comportamento_df['page_views'], comportamento_df['taxa_conversao'], \n",
        "                               alpha=0.7, s=100, c=comportamento_df['total_eventos'], \n",
        "                               cmap='viridis', edgecolors='black')\n",
        "    axes[0, 1].set_title('ğŸ¯ Taxa de ConversÃ£o vs Page Views', fontweight='bold')\n",
        "    axes[0, 1].set_xlabel('Page Views')\n",
        "    axes[0, 1].set_ylabel('Taxa de ConversÃ£o')\n",
        "    axes[0, 1].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Adicionar colorbar\n",
        "    cbar = plt.colorbar(scatter, ax=axes[0, 1])\n",
        "    cbar.set_label('Total de Eventos')\n",
        "\n",
        "# GrÃ¡fico 3: Clusters de usuÃ¡rios\n",
        "if comportamento_df is not None and 'cluster' in comportamento_df.columns:\n",
        "    cluster_colors = {0: 'lightcoral', 1: 'gold', 2: 'lightgreen'}\n",
        "    cluster_labels = {0: 'Passivos', 1: 'Ativos Baixa Conv.', 2: 'Ativos Convertidos'}\n",
        "    \n",
        "    for cluster_id in range(3):\n",
        "        cluster_data = comportamento_df[comportamento_df['cluster'] == cluster_id]\n",
        "        axes[0, 2].scatter(cluster_data['total_eventos'], cluster_data['taxa_conversao'],\n",
        "                          c=cluster_colors[cluster_id], label=cluster_labels[cluster_id],\n",
        "                          alpha=0.7, s=100, edgecolors='black')\n",
        "    \n",
        "    axes[0, 2].set_title('ğŸ¯ Clusters de UsuÃ¡rios', fontweight='bold')\n",
        "    axes[0, 2].set_xlabel('Total de Eventos')\n",
        "    axes[0, 2].set_ylabel('Taxa de ConversÃ£o')\n",
        "    axes[0, 2].legend()\n",
        "    axes[0, 2].grid(True, alpha=0.3)\n",
        "\n",
        "# GrÃ¡fico 4: DistribuiÃ§Ã£o de valores de compra (PostgreSQL)\n",
        "if usuarios_transacionais is not None and not usuarios_transacionais.empty:\n",
        "    axes[1, 0].hist(usuarios_transacionais['valor_total_compras'], bins=15, alpha=0.7, \n",
        "                   color='lightgreen', edgecolor='black')\n",
        "    axes[1, 0].set_title('ğŸ’° DistribuiÃ§Ã£o de Valores de Compra', fontweight='bold')\n",
        "    axes[1, 0].set_xlabel('Valor Total Compras (R$)')\n",
        "    axes[1, 0].set_ylabel('FrequÃªncia')\n",
        "    axes[1, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Adicionar estatÃ­sticas\n",
        "    mean_value = usuarios_transacionais['valor_total_compras'].mean()\n",
        "    axes[1, 0].axvline(mean_value, color='red', linestyle='--', linewidth=2, label=f'MÃ©dia: R$ {mean_value:,.0f}')\n",
        "    axes[1, 0].legend()\n",
        "\n",
        "# GrÃ¡fico 5: Segmentos de usuÃ¡rios\n",
        "if usuarios_transacionais is not None and not usuarios_transacionais.empty:\n",
        "    segmentos = usuarios_transacionais['segmento'].value_counts()\n",
        "    colors = ['gold', 'lightblue', 'lightcoral', 'lightgreen']\n",
        "    wedges, texts, autotexts = axes[1, 1].pie(segmentos.values, labels=segmentos.index, \n",
        "                                            autopct='%1.1f%%', startangle=90, colors=colors)\n",
        "    axes[1, 1].set_title('ğŸ‘¥ DistribuiÃ§Ã£o por Segmento', fontweight='bold')\n",
        "    \n",
        "    # Melhorar legibilidade\n",
        "    for autotext in autotexts:\n",
        "        autotext.set_color('white')\n",
        "        autotext.set_fontweight('bold')\n",
        "\n",
        "# GrÃ¡fico 6: Probabilidade de churn\n",
        "if usuarios_transacionais is not None and 'probabilidade_churn' in usuarios_transacionais.columns:\n",
        "    # Criar bins para probabilidade de churn\n",
        "    bins = [0, 0.3, 0.7, 1.0]\n",
        "    labels = ['Baixo Risco', 'MÃ©dio Risco', 'Alto Risco']\n",
        "    usuarios_transacionais['risco_churn'] = pd.cut(usuarios_transacionais['probabilidade_churn'], \n",
        "                                                  bins=bins, labels=labels, include_lowest=True)\n",
        "    \n",
        "    risco_counts = usuarios_transacionais['risco_churn'].value_counts()\n",
        "    colors = ['lightgreen', 'gold', 'lightcoral']\n",
        "    \n",
        "    bars = axes[1, 2].bar(risco_counts.index, risco_counts.values, color=colors, alpha=0.7, edgecolor='black')\n",
        "    axes[1, 2].set_title('ğŸš¨ DistribuiÃ§Ã£o de Risco de Churn', fontweight='bold')\n",
        "    axes[1, 2].set_ylabel('NÃºmero de UsuÃ¡rios')\n",
        "    axes[1, 2].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Adicionar valores nas barras\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        axes[1, 2].text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
        "                       f'{int(height)}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "# Ajustar layout\n",
        "plt.tight_layout()\n",
        "\n",
        "# Salvar grÃ¡fico\n",
        "plt.savefig('dashboard_analise_preditiva.png', dpi=300, bbox_inches='tight')\n",
        "print(\"âœ… Dashboard salvo como 'dashboard_analise_preditiva.png'\")\n",
        "\n",
        "# Mostrar grÃ¡fico\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nğŸ‰ VisualizaÃ§Ãµes criadas com sucesso!\")\n",
        "print(\"ğŸ“Š Dashboard completo com anÃ¡lises de MongoDB e PostgreSQL\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¯ Parte 6: Sistema de RecomendaÃ§Ãµes\n",
        "\n",
        "### Objetivo: Gerar recomendaÃ§Ãµes personalizadas baseadas na anÃ¡lise preditiva\n",
        "\n",
        "Vamos implementar:\n",
        "1. **Algoritmo colaborativo simples**\n",
        "2. **Scoring baseado em comportamento**\n",
        "3. **RecomendaÃ§Ãµes por cluster**\n",
        "4. **IntegraÃ§Ã£o MongoDB + PostgreSQL**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ¯ Sistema de RecomendaÃ§Ãµes\n",
        "print(\"ğŸ¯ Gerando recomendaÃ§Ãµes personalizadas...\")\n",
        "\n",
        "def gerar_recomendacoes(usuario_id, comportamento_df, usuarios_transacionais):\n",
        "    \"\"\"Gerar recomendaÃ§Ãµes para um usuÃ¡rio especÃ­fico\"\"\"\n",
        "    \n",
        "    # Produtos disponÃ­veis (simulados)\n",
        "    produtos_disponiveis = [\n",
        "        {'id': 'P001', 'nome': 'Smartphone Galaxy S24', 'categoria': 'smartphones', 'preco': 2999.99},\n",
        "        {'id': 'P002', 'nome': 'iPhone 15 Pro', 'categoria': 'smartphones', 'preco': 8999.99},\n",
        "        {'id': 'P003', 'nome': 'Notebook Dell XPS 13', 'categoria': 'notebooks', 'preco': 5999.99},\n",
        "        {'id': 'P004', 'nome': 'Tablet iPad Air', 'categoria': 'tablets', 'preco': 3999.99},\n",
        "        {'id': 'P005', 'nome': 'Smartphone Xiaomi 13', 'categoria': 'smartphones', 'preco': 1999.99},\n",
        "        {'id': 'P006', 'nome': 'Notebook MacBook Air', 'categoria': 'notebooks', 'preco': 7999.99},\n",
        "        {'id': 'P007', 'nome': 'Tablet Samsung Galaxy Tab', 'categoria': 'tablets', 'preco': 2499.99},\n",
        "        {'id': 'P008', 'nome': 'Smartphone Pixel 8', 'categoria': 'smartphones', 'preco': 3499.99}\n",
        "    ]\n",
        "    \n",
        "    # Buscar dados do usuÃ¡rio\n",
        "    user_comportamento = comportamento_df[comportamento_df['usuario_id'] == usuario_id] if comportamento_df is not None else None\n",
        "    user_transacional = usuarios_transacionais[usuarios_transacionais['usuario_id'] == usuario_id] if usuarios_transacionais is not None else None\n",
        "    \n",
        "    recomendacoes = []\n",
        "    \n",
        "    for produto in produtos_disponiveis:\n",
        "        score = 0.0\n",
        "        motivos = []\n",
        "        \n",
        "        # Score baseado em comportamento (MongoDB)\n",
        "        if user_comportamento is not None and not user_comportamento.empty:\n",
        "            user_data = user_comportamento.iloc[0]\n",
        "            \n",
        "            # UsuÃ¡rios ativos tÃªm preferÃªncia por produtos similares\n",
        "            if user_data['total_eventos'] > comportamento_df['total_eventos'].mean():\n",
        "                score += 0.3\n",
        "                motivos.append(\"usuÃ¡rio_ativo\")\n",
        "            \n",
        "            # UsuÃ¡rios com alta conversÃ£o preferem produtos premium\n",
        "            if user_data['taxa_conversao'] > comportamento_df['taxa_conversao'].mean():\n",
        "                if produto['preco'] > 5000:\n",
        "                    score += 0.2\n",
        "                    motivos.append(\"preferencia_premium\")\n",
        "                else:\n",
        "                    score += 0.1\n",
        "                    motivos.append(\"produto_acessivel\")\n",
        "            \n",
        "            # UsuÃ¡rios que visualizam muitos produtos tÃªm preferÃªncia diversificada\n",
        "            if user_data['produtos_unicos'] > comportamento_df['produtos_unicos'].mean():\n",
        "                score += 0.15\n",
        "                motivos.append(\"interesse_diversificado\")\n",
        "        \n",
        "        # Score baseado em dados transacionais (PostgreSQL)\n",
        "        if user_transacional is not None and not user_transacional.empty:\n",
        "            user_data = user_transacional.iloc[0]\n",
        "            \n",
        "            # UsuÃ¡rios high_value preferem produtos caros\n",
        "            if user_data['segmento'] == 'high_value':\n",
        "                if produto['preco'] > 5000:\n",
        "                    score += 0.4\n",
        "                    motivos.append(\"segmento_high_value\")\n",
        "                else:\n",
        "                    score += 0.1\n",
        "                    motivos.append(\"produto_economico\")\n",
        "            \n",
        "            # UsuÃ¡rios com muitos pedidos preferem produtos populares\n",
        "            if user_data['total_pedidos'] > usuarios_transacionais['total_pedidos'].mean():\n",
        "                score += 0.2\n",
        "                motivos.append(\"cliente_frequente\")\n",
        "            \n",
        "            # UsuÃ¡rios com baixo risco de churn tÃªm preferÃªncia por produtos similares\n",
        "            if 'probabilidade_churn' in user_data and user_data['probabilidade_churn'] < 0.3:\n",
        "                score += 0.15\n",
        "                motivos.append(\"baixo_risco_churn\")\n",
        "        \n",
        "        # Score baseado em cluster (se disponÃ­vel)\n",
        "        if user_comportamento is not None and 'cluster' in user_comportamento.columns:\n",
        "            cluster = user_comportamento.iloc[0]['cluster']\n",
        "            \n",
        "            if cluster == 2:  # UsuÃ¡rios ativos e convertidos\n",
        "                score += 0.25\n",
        "                motivos.append(\"cluster_ativo_convertido\")\n",
        "            elif cluster == 1:  # UsuÃ¡rios ativos mas baixa conversÃ£o\n",
        "                if produto['preco'] < 3000:  # Produtos mais baratos\n",
        "                    score += 0.2\n",
        "                    motivos.append(\"cluster_ativo_baixa_conv\")\n",
        "            elif cluster == 0:  # UsuÃ¡rios passivos\n",
        "                if produto['preco'] < 2000:  # Produtos muito baratos\n",
        "                    score += 0.15\n",
        "                    motivos.append(\"cluster_passivo\")\n",
        "        \n",
        "        # Adicionar score baseado em categoria (simulaÃ§Ã£o de preferÃªncia)\n",
        "        categoria_scores = {'smartphones': 0.1, 'notebooks': 0.05, 'tablets': 0.08}\n",
        "        score += categoria_scores.get(produto['categoria'], 0.02)\n",
        "        \n",
        "        # Adicionar ruÃ­do aleatÃ³rio para simular variaÃ§Ã£o\n",
        "        score += random.uniform(-0.1, 0.1)\n",
        "        score = max(0, min(1, score))  # Manter entre 0 e 1\n",
        "        \n",
        "        recomendacoes.append({\n",
        "            'produto_id': produto['id'],\n",
        "            'nome': produto['nome'],\n",
        "            'categoria': produto['categoria'],\n",
        "            'preco': produto['preco'],\n",
        "            'score': score,\n",
        "            'motivos': motivos\n",
        "        })\n",
        "    \n",
        "    # Ordenar por score e retornar top 5\n",
        "    recomendacoes.sort(key=lambda x: x['score'], reverse=True)\n",
        "    return recomendacoes[:5]\n",
        "\n",
        "# Gerar recomendaÃ§Ãµes para alguns usuÃ¡rios\n",
        "usuarios_exemplo = ['U001', 'U002', 'U003', 'U004', 'U005']\n",
        "\n",
        "print(\"ğŸ¯ RecomendaÃ§Ãµes Personalizadas:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for usuario in usuarios_exemplo:\n",
        "    print(f\"\\nğŸ‘¤ UsuÃ¡rio: {usuario}\")\n",
        "    \n",
        "    # Buscar informaÃ§Ãµes do usuÃ¡rio\n",
        "    user_info = \"\"\n",
        "    if comportamento_df is not None:\n",
        "        user_comp = comportamento_df[comportamento_df['usuario_id'] == usuario]\n",
        "        if not user_comp.empty:\n",
        "            user_info += f\"Eventos: {user_comp.iloc[0]['total_eventos']}, \"\n",
        "            user_info += f\"ConversÃ£o: {user_comp.iloc[0]['taxa_conversao']:.1%}\"\n",
        "            if 'cluster' in user_comp.columns:\n",
        "                cluster_names = {0: 'Passivo', 1: 'Ativo Baixa Conv.', 2: 'Ativo Convertido'}\n",
        "                user_info += f\", Cluster: {cluster_names.get(user_comp.iloc[0]['cluster'], 'N/A')}\"\n",
        "    \n",
        "    if usuarios_transacionais is not None:\n",
        "        user_trans = usuarios_transacionais[usuarios_transacionais['usuario_id'] == usuario]\n",
        "        if not user_trans.empty:\n",
        "            user_info += f\", Segmento: {user_trans.iloc[0]['segmento']}\"\n",
        "            if 'probabilidade_churn' in user_trans.columns:\n",
        "                user_info += f\", Risco Churn: {user_trans.iloc[0]['probabilidade_churn']:.1%}\"\n",
        "    \n",
        "    print(f\"ğŸ“Š Perfil: {user_info}\")\n",
        "    \n",
        "    # Gerar recomendaÃ§Ãµes\n",
        "    recomendacoes = gerar_recomendacoes(usuario, comportamento_df, usuarios_transacionais)\n",
        "    \n",
        "    print(\"ğŸ¯ Top 3 RecomendaÃ§Ãµes:\")\n",
        "    for i, rec in enumerate(recomendacoes[:3], 1):\n",
        "        print(f\"  {i}. {rec['nome']}\")\n",
        "        print(f\"     PreÃ§o: R$ {rec['preco']:,.2f}\")\n",
        "        print(f\"     Score: {rec['score']:.2f}\")\n",
        "        print(f\"     Motivos: {', '.join(rec['motivos'])}\")\n",
        "        print()\n",
        "\n",
        "print(\"âœ… Sistema de recomendaÃ§Ãµes implementado com sucesso!\")\n",
        "print(\"ğŸ¯ RecomendaÃ§Ãµes baseadas em anÃ¡lise preditiva de MongoDB + PostgreSQL\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
