{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üéØ Demonstra√ß√£o Pr√°tica - An√°lise Preditiva E-commerce\n",
        "\n",
        "## Sistema de Recomenda√ß√£o de Produtos com MongoDB + PostgreSQL\n",
        "\n",
        "Este notebook demonstra uma aplica√ß√£o pr√°tica de an√°lise preditiva para um sistema de recomenda√ß√£o de produtos e-commerce, utilizando uma arquitetura h√≠brida com MongoDB e PostgreSQL.\n",
        "\n",
        "### üìã Objetivos da Demonstra√ß√£o:\n",
        "- **An√°lise Descritiva:** Entender o comportamento dos usu√°rios e produtos\n",
        "- **An√°lise Preditiva:** Predizer probabilidade de compra e churn\n",
        "- **Clustering:** Segmentar usu√°rios por comportamento\n",
        "- **Recomenda√ß√µes:** Gerar recomenda√ß√µes personalizadas\n",
        "- **Visualiza√ß√µes:** Criar dashboards interativos\n",
        "\n",
        "### üõ†Ô∏è Tecnologias Utilizadas:\n",
        "- **MongoDB:** Dados n√£o estruturados e comportamento\n",
        "- **PostgreSQL:** Dados transacionais e relat√≥rios\n",
        "- **Python:** An√°lise de dados e machine learning\n",
        "- **Scikit-learn:** Algoritmos de ML\n",
        "- **Matplotlib/Seaborn:** Visualiza√ß√µes\n",
        "- **Pandas:** Manipula√ß√£o de dados\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üì¶ Importar Bibliotecas Necess√°rias\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta\n",
        "import random\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Machine Learning\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Bancos de dados\n",
        "from pymongo import MongoClient\n",
        "import psycopg2\n",
        "from psycopg2.extras import RealDictCursor\n",
        "\n",
        "# Configura√ß√µes de visualiza√ß√£o\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "\n",
        "print(\"‚úÖ Bibliotecas importadas com sucesso!\")\n",
        "print(\"üöÄ Pronto para iniciar a demonstra√ß√£o!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üóÑÔ∏è Parte 1: Conex√£o com Bancos de Dados\n",
        "\n",
        "### MongoDB - Dados N√£o Estruturados\n",
        "MongoDB ser√° usado para armazenar:\n",
        "- **Produtos:** Caracter√≠sticas flex√≠veis e reviews\n",
        "- **Comportamento:** Eventos de navega√ß√£o e intera√ß√£o\n",
        "- **Recomenda√ß√µes:** Scores e matrizes de similaridade\n",
        "\n",
        "### PostgreSQL - Dados Transacionais\n",
        "PostgreSQL ser√° usado para:\n",
        "- **Usu√°rios:** Dados pessoais e segmenta√ß√£o\n",
        "- **Pedidos:** Transa√ß√µes e hist√≥rico de compras\n",
        "- **Relat√≥rios:** An√°lises estruturadas e KPIs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üîå Conectar ao MongoDB\n",
        "try:\n",
        "    mongo_client = MongoClient('mongodb://localhost:27017')\n",
        "    mongo_db = mongo_client['ecommerce_demo']\n",
        "    print(\"‚úÖ Conectado ao MongoDB com sucesso!\")\n",
        "    \n",
        "    # Testar conex√£o\n",
        "    mongo_db.command('ping')\n",
        "    print(\"‚úÖ Ping MongoDB: OK\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Erro ao conectar MongoDB: {e}\")\n",
        "    print(\"üí° Certifique-se de que o MongoDB est√° rodando\")\n",
        "    mongo_client = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üîå Conectar ao PostgreSQL\n",
        "try:\n",
        "    postgres_conn = psycopg2.connect(\n",
        "        host='localhost',\n",
        "        database='ecommerce_demo',\n",
        "        user='postgres',\n",
        "        password='postgres'\n",
        "    )\n",
        "    postgres_cursor = postgres_conn.cursor(cursor_factory=RealDictCursor)\n",
        "    print(\"‚úÖ Conectado ao PostgreSQL com sucesso!\")\n",
        "    \n",
        "    # Testar conex√£o\n",
        "    postgres_cursor.execute(\"SELECT version();\")\n",
        "    version = postgres_cursor.fetchone()\n",
        "    print(f\"‚úÖ PostgreSQL Version: {version[0][:50]}...\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Erro ao conectar PostgreSQL: {e}\")\n",
        "    print(\"üí° Certifique-se de que o PostgreSQL est√° rodando e o banco existe\")\n",
        "    postgres_conn = None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Parte 2: An√°lise Descritiva - MongoDB\n",
        "\n",
        "### Objetivo: Entender o comportamento dos usu√°rios atrav√©s de dados n√£o estruturados\n",
        "\n",
        "Vamos analisar:\n",
        "1. **Produtos mais visualizados**\n",
        "2. **Padr√µes de navega√ß√£o**\n",
        "3. **Eventos de convers√£o**\n",
        "4. **Segmenta√ß√£o por comportamento**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üìä An√°lise de Comportamento - MongoDB\n",
        "if mongo_client:\n",
        "    print(\"üîç Analisando comportamento dos usu√°rios...\")\n",
        "    \n",
        "    # Pipeline para an√°lise de comportamento\n",
        "    pipeline = [\n",
        "        {\"$unwind\": \"$eventos\"},\n",
        "        {\"$group\": {\n",
        "            \"_id\": \"$usuario_id\",\n",
        "            \"total_eventos\": {\"$sum\": 1},\n",
        "            \"page_views\": {\n",
        "                \"$sum\": {\"$cond\": [{\"$eq\": [\"$eventos.tipo\", \"page_view\"]}, 1, 0]}\n",
        "            },\n",
        "            \"clicks\": {\n",
        "                \"$sum\": {\"$cond\": [{\"$eq\": [\"$eventos.tipo\", \"click\"]}, 1, 0]}\n",
        "            },\n",
        "            \"add_to_cart\": {\n",
        "                \"$sum\": {\"$cond\": [{\"$eq\": [\"$eventos.tipo\", \"add_to_cart\"]}, 1, 0]}\n",
        "            },\n",
        "            \"searches\": {\n",
        "                \"$sum\": {\"$cond\": [{\"$eq\": [\"$eventos.tipo\", \"search\"]}, 1, 0]}\n",
        "            },\n",
        "            \"tempo_total\": {\"$sum\": \"$eventos.tempo_pagina\"},\n",
        "            \"produtos_unicos\": {\"$addToSet\": \"$eventos.produto_id\"}\n",
        "        }},\n",
        "        {\"$project\": {\n",
        "            \"usuario_id\": \"$_id\",\n",
        "            \"total_eventos\": 1,\n",
        "            \"page_views\": 1,\n",
        "            \"clicks\": 1,\n",
        "            \"add_to_cart\": 1,\n",
        "            \"searches\": 1,\n",
        "            \"tempo_total\": 1,\n",
        "            \"produtos_unicos\": {\"$size\": \"$produtos_unicos\"},\n",
        "            \"taxa_conversao\": {\n",
        "                \"$cond\": [\n",
        "                    {\"$gt\": [\"$page_views\", 0]},\n",
        "                    {\"$divide\": [\"$add_to_cart\", \"$page_views\"]},\n",
        "                    0\n",
        "                ]\n",
        "            },\n",
        "            \"tempo_medio_evento\": {\n",
        "                \"$cond\": [\n",
        "                    {\"$gt\": [\"$total_eventos\", 0]},\n",
        "                    {\"$divide\": [\"$tempo_total\", \"$total_eventos\"]},\n",
        "                    0\n",
        "                ]\n",
        "            }\n",
        "        }},\n",
        "        {\"$sort\": {\"total_eventos\": -1}}\n",
        "    ]\n",
        "    \n",
        "    # Executar pipeline\n",
        "    comportamento_data = list(mongo_db.usuarios_comportamento.aggregate(pipeline))\n",
        "    \n",
        "    if comportamento_data:\n",
        "        comportamento_df = pd.DataFrame(comportamento_data)\n",
        "        print(f\"‚úÖ Analisados {len(comportamento_df)} usu√°rios\")\n",
        "        print(\"\\nüìà Resumo do Comportamento:\")\n",
        "        print(comportamento_df.describe().round(2))\n",
        "        \n",
        "        # Mostrar top usu√°rios mais ativos\n",
        "        print(\"\\nüèÜ Top 5 Usu√°rios Mais Ativos:\")\n",
        "        top_usuarios = comportamento_df.head()\n",
        "        for _, user in top_usuarios.iterrows():\n",
        "            print(f\"  {user['usuario_id']}: {user['total_eventos']} eventos, \"\n",
        "                  f\"{user['taxa_conversao']:.1%} convers√£o\")\n",
        "    else:\n",
        "        print(\"‚ùå Nenhum dado de comportamento encontrado\")\n",
        "        comportamento_df = None\n",
        "else:\n",
        "    print(\"‚ùå MongoDB n√£o dispon√≠vel - usando dados simulados\")\n",
        "    # Criar dados simulados para demonstra√ß√£o\n",
        "    np.random.seed(42)\n",
        "    comportamento_df = pd.DataFrame({\n",
        "        'usuario_id': [f'U{i:03d}' for i in range(1, 21)],\n",
        "        'total_eventos': np.random.poisson(15, 20),\n",
        "        'page_views': np.random.poisson(10, 20),\n",
        "        'clicks': np.random.poisson(8, 20),\n",
        "        'add_to_cart': np.random.poisson(2, 20),\n",
        "        'searches': np.random.poisson(3, 20),\n",
        "        'produtos_unicos': np.random.randint(1, 8, 20),\n",
        "        'taxa_conversao': np.random.beta(2, 8, 20),\n",
        "        'tempo_medio_evento': np.random.normal(45, 15, 20)\n",
        "    })\n",
        "    print(f\"‚úÖ Criados {len(comportamento_df)} usu√°rios simulados\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Parte 3: An√°lise Preditiva - Clustering de Usu√°rios\n",
        "\n",
        "### Objetivo: Segmentar usu√°rios por comportamento usando K-Means\n",
        "\n",
        "Vamos identificar:\n",
        "1. **Usu√°rios Ativos e Convertidos** üî•\n",
        "2. **Usu√°rios Ativos mas Baixa Convers√£o** üëÄ  \n",
        "3. **Usu√°rios Passivos** üò¥\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üéØ Clustering de Usu√°rios com K-Means\n",
        "if comportamento_df is not None and not comportamento_df.empty:\n",
        "    print(\"üîç Aplicando clustering K-Means...\")\n",
        "    \n",
        "    # Preparar features para clustering\n",
        "    features = ['total_eventos', 'page_views', 'clicks', 'add_to_cart', 'produtos_unicos', 'taxa_conversao']\n",
        "    X = comportamento_df[features].fillna(0)\n",
        "    \n",
        "    # Normalizar dados\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "    \n",
        "    # Aplicar K-Means\n",
        "    kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
        "    comportamento_df['cluster'] = kmeans.fit_predict(X_scaled)\n",
        "    \n",
        "    # An√°lise dos clusters\n",
        "    cluster_analysis = comportamento_df.groupby('cluster')[features].mean()\n",
        "    \n",
        "    print(\"üìä An√°lise de Clusters:\")\n",
        "    print(cluster_analysis.round(2))\n",
        "    \n",
        "    # Interpretar clusters\n",
        "    print(\"\\nüè∑Ô∏è Interpreta√ß√£o dos Clusters:\")\n",
        "    cluster_names = {\n",
        "        0: \"üò¥ Usu√°rios Passivos\",\n",
        "        1: \"üëÄ Usu√°rios Ativos mas Baixa Convers√£o\", \n",
        "        2: \"üî• Usu√°rios Ativos e Convertidos\"\n",
        "    }\n",
        "    \n",
        "    for cluster_id in range(3):\n",
        "        cluster_data = comportamento_df[comportamento_df['cluster'] == cluster_id]\n",
        "        avg_events = cluster_data['total_eventos'].mean()\n",
        "        avg_conversion = cluster_data['taxa_conversao'].mean()\n",
        "        \n",
        "        print(f\"\\n{cluster_names[cluster_id]}:\")\n",
        "        print(f\"  Usu√°rios: {len(cluster_data)}\")\n",
        "        print(f\"  Eventos m√©dios: {avg_events:.1f}\")\n",
        "        print(f\"  Taxa convers√£o: {avg_conversion:.1%}\")\n",
        "        print(f\"  Produtos √∫nicos: {cluster_data['produtos_unicos'].mean():.1f}\")\n",
        "        \n",
        "        # Mostrar alguns usu√°rios do cluster\n",
        "        sample_users = cluster_data['usuario_id'].head(3).tolist()\n",
        "        print(f\"  Exemplos: {', '.join(sample_users)}\")\n",
        "    \n",
        "    print(f\"\\n‚úÖ Clustering conclu√≠do! {len(comportamento_df)} usu√°rios segmentados em 3 grupos\")\n",
        "else:\n",
        "    print(\"‚ùå Dados de comportamento n√£o dispon√≠veis para clustering\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìà Parte 4: An√°lise Preditiva - PostgreSQL\n",
        "\n",
        "### Objetivo: Predizer churn de usu√°rios baseado em dados transacionais\n",
        "\n",
        "Vamos analisar:\n",
        "1. **Hist√≥rico de compras**\n",
        "2. **Padr√µes de gastos**\n",
        "3. **Frequ√™ncia de compras**\n",
        "4. **Probabilidade de churn**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üìà An√°lise Preditiva - PostgreSQL\n",
        "if postgres_conn:\n",
        "    print(\"üîç Analisando dados transacionais...\")\n",
        "    \n",
        "    # Query para an√°lise de usu√°rios\n",
        "    query = \"\"\"\n",
        "        SELECT \n",
        "            u.usuario_id,\n",
        "            u.nome,\n",
        "            u.segmento,\n",
        "            u.valor_total_compras,\n",
        "            COUNT(p.id) as total_pedidos,\n",
        "            AVG(p.valor_total) as ticket_medio,\n",
        "            COUNT(DISTINCT ip.produto_id) as produtos_unicos,\n",
        "            MAX(p.data_pedido) as ultima_compra,\n",
        "            EXTRACT(DAYS FROM NOW() - MAX(p.data_pedido)) as dias_sem_comprar,\n",
        "            COUNT(CASE WHEN p.status = 'concluido' THEN 1 END) as pedidos_concluidos,\n",
        "            COUNT(CASE WHEN p.status = 'pendente' THEN 1 END) as pedidos_pendentes,\n",
        "            STDDEV(p.valor_total) as variabilidade_gastos\n",
        "        FROM usuarios u\n",
        "        LEFT JOIN pedidos p ON u.id = p.usuario_id\n",
        "        LEFT JOIN itens_pedido ip ON p.id = ip.pedido_id\n",
        "        GROUP BY u.usuario_id, u.nome, u.segmento, u.valor_total_compras\n",
        "        ORDER BY u.valor_total_compras DESC\n",
        "    \"\"\"\n",
        "    \n",
        "    postgres_cursor.execute(query)\n",
        "    usuarios_transacionais = pd.DataFrame(postgres_cursor.fetchall())\n",
        "    \n",
        "    if not usuarios_transacionais.empty:\n",
        "        print(f\"‚úÖ Analisados {len(usuarios_transacionais)} usu√°rios transacionais\")\n",
        "        \n",
        "        # Preparar dados para predi√ß√£o de churn\n",
        "        usuarios_transacionais['dias_sem_comprar'] = usuarios_transacionais['dias_sem_comprar'].fillna(365)\n",
        "        usuarios_transacionais['ticket_medio'] = usuarios_transacionais['ticket_medio'].fillna(0)\n",
        "        usuarios_transacionais['produtos_unicos'] = usuarios_transacionais['produtos_unicos'].fillna(0)\n",
        "        usuarios_transacionais['variabilidade_gastos'] = usuarios_transacionais['variabilidade_gastos'].fillna(0)\n",
        "        \n",
        "        # Criar vari√°vel target (churn = dias sem comprar > 30)\n",
        "        usuarios_transacionais['churn'] = (usuarios_transacionais['dias_sem_comprar'] > 30).astype(int)\n",
        "        \n",
        "        print(\"\\nüìä Estat√≠sticas dos Usu√°rios:\")\n",
        "        print(f\"  Valor m√©dio de compras: R$ {usuarios_transacionais['valor_total_compras'].mean():,.2f}\")\n",
        "        print(f\"  Pedidos m√©dios por usu√°rio: {usuarios_transacionais['total_pedidos'].mean():.1f}\")\n",
        "        print(f\"  Ticket m√©dio: R$ {usuarios_transacionais['ticket_medio'].mean():,.2f}\")\n",
        "        print(f\"  Taxa de churn: {usuarios_transacionais['churn'].mean():.1%}\")\n",
        "        \n",
        "        # Mostrar usu√°rios com maior risco de churn\n",
        "        risco_churn = usuarios_transacionais[usuarios_transacionais['churn'] == 1].sort_values('dias_sem_comprar', ascending=False)\n",
        "        print(f\"\\n‚ö†Ô∏è Usu√°rios com Risco de Churn ({len(risco_churn)} usu√°rios):\")\n",
        "        for _, user in risco_churn.head(5).iterrows():\n",
        "            print(f\"  {user['nome']}: {user['dias_sem_comprar']:.0f} dias sem comprar, \"\n",
        "                  f\"R$ {user['valor_total_compras']:,.2f} hist√≥rico\")\n",
        "        \n",
        "    else:\n",
        "        print(\"‚ùå Nenhum dado transacional encontrado\")\n",
        "        usuarios_transacionais = None\n",
        "else:\n",
        "    print(\"‚ùå PostgreSQL n√£o dispon√≠vel - usando dados simulados\")\n",
        "    # Criar dados simulados para demonstra√ß√£o\n",
        "    np.random.seed(42)\n",
        "    usuarios_transacionais = pd.DataFrame({\n",
        "        'usuario_id': [f'U{i:03d}' for i in range(1, 21)],\n",
        "        'nome': [f'Usu√°rio {i}' for i in range(1, 21)],\n",
        "        'segmento': np.random.choice(['high_value', 'medium_value', 'low_value', 'new_user'], 20),\n",
        "        'valor_total_compras': np.random.exponential(2000, 20),\n",
        "        'total_pedidos': np.random.poisson(5, 20),\n",
        "        'ticket_medio': np.random.normal(500, 200, 20),\n",
        "        'produtos_unicos': np.random.randint(1, 10, 20),\n",
        "        'dias_sem_comprar': np.random.exponential(30, 20),\n",
        "        'pedidos_concluidos': np.random.poisson(4, 20),\n",
        "        'pedidos_pendentes': np.random.poisson(1, 20),\n",
        "        'variabilidade_gastos': np.random.exponential(100, 20)\n",
        "    })\n",
        "    usuarios_transacionais['churn'] = (usuarios_transacionais['dias_sem_comprar'] > 30).astype(int)\n",
        "    print(f\"‚úÖ Criados {len(usuarios_transacionais)} usu√°rios transacionais simulados\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üéØ Modelo de Predi√ß√£o de Churn\n",
        "if usuarios_transacionais is not None and not usuarios_transacionais.empty:\n",
        "    print(\"ü§ñ Treinando modelo de predi√ß√£o de churn...\")\n",
        "    \n",
        "    # Features para o modelo\n",
        "    features = ['valor_total_compras', 'total_pedidos', 'ticket_medio', 'produtos_unicos', 'dias_sem_comprar', 'variabilidade_gastos']\n",
        "    X = usuarios_transacionais[features].fillna(0)\n",
        "    y = usuarios_transacionais['churn']\n",
        "    \n",
        "    # Dividir dados\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "    \n",
        "    # Treinar modelo Random Forest\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=5)\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    # Fazer predi√ß√µes\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "    \n",
        "    # Avaliar modelo\n",
        "    print(\"üìà Relat√≥rio de Classifica√ß√£o:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    \n",
        "    # Import√¢ncia das features\n",
        "    feature_importance = pd.DataFrame({\n",
        "        'feature': features,\n",
        "        'importance': model.feature_importances_\n",
        "    }).sort_values('importance', ascending=False)\n",
        "    \n",
        "    print(\"\\nüîç Import√¢ncia das Features:\")\n",
        "    print(feature_importance.to_string(index=False))\n",
        "    \n",
        "    # Predi√ß√µes para todos os usu√°rios\n",
        "    usuarios_transacionais['probabilidade_churn'] = model.predict_proba(X)[:, 1]\n",
        "    usuarios_transacionais['predicao_churn'] = model.predict(X)\n",
        "    \n",
        "    # Mostrar usu√°rios com maior probabilidade de churn\n",
        "    risco_alto = usuarios_transacionais[usuarios_transacionais['probabilidade_churn'] > 0.7].sort_values('probabilidade_churn', ascending=False)\n",
        "    print(f\"\\nüö® Usu√°rios com Alto Risco de Churn ({len(risco_alto)} usu√°rios):\")\n",
        "    for _, user in risco_alto.head(5).iterrows():\n",
        "        print(f\"  {user['nome']}: {user['probabilidade_churn']:.1%} probabilidade, \"\n",
        "              f\"{user['dias_sem_comprar']:.0f} dias sem comprar\")\n",
        "    \n",
        "    print(f\"\\n‚úÖ Modelo treinado com {len(X_train)} amostras de treino e {len(X_test)} de teste\")\n",
        "else:\n",
        "    print(\"‚ùå Dados transacionais n√£o dispon√≠veis para predi√ß√£o de churn\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Parte 5: Visualiza√ß√µes Interativas\n",
        "\n",
        "### Objetivo: Criar dashboards visuais para an√°lise dos resultados\n",
        "\n",
        "Vamos criar:\n",
        "1. **Gr√°ficos de comportamento**\n",
        "2. **An√°lise de clusters**\n",
        "3. **Predi√ß√µes de churn**\n",
        "4. **Compara√ß√£o entre bancos**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üìä Criar Visualiza√ß√µes Interativas\n",
        "print(\"üé® Criando visualiza√ß√µes...\")\n",
        "\n",
        "# Configurar figura com subplots\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "fig.suptitle('üéØ Dashboard - An√°lise Preditiva E-commerce', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Gr√°fico 1: Distribui√ß√£o de eventos por usu√°rio (MongoDB)\n",
        "if comportamento_df is not None and not comportamento_df.empty:\n",
        "    axes[0, 0].hist(comportamento_df['total_eventos'], bins=15, alpha=0.7, color='skyblue', edgecolor='black')\n",
        "    axes[0, 0].set_title('üì± Distribui√ß√£o de Eventos por Usu√°rio', fontweight='bold')\n",
        "    axes[0, 0].set_xlabel('Total de Eventos')\n",
        "    axes[0, 0].set_ylabel('Frequ√™ncia')\n",
        "    axes[0, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Adicionar estat√≠sticas\n",
        "    mean_events = comportamento_df['total_eventos'].mean()\n",
        "    axes[0, 0].axvline(mean_events, color='red', linestyle='--', linewidth=2, label=f'M√©dia: {mean_events:.1f}')\n",
        "    axes[0, 0].legend()\n",
        "\n",
        "# Gr√°fico 2: Taxa de convers√£o vs Page Views\n",
        "if comportamento_df is not None and not comportamento_df.empty:\n",
        "    scatter = axes[0, 1].scatter(comportamento_df['page_views'], comportamento_df['taxa_conversao'], \n",
        "                               alpha=0.7, s=100, c=comportamento_df['total_eventos'], \n",
        "                               cmap='viridis', edgecolors='black')\n",
        "    axes[0, 1].set_title('üéØ Taxa de Convers√£o vs Page Views', fontweight='bold')\n",
        "    axes[0, 1].set_xlabel('Page Views')\n",
        "    axes[0, 1].set_ylabel('Taxa de Convers√£o')\n",
        "    axes[0, 1].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Adicionar colorbar\n",
        "    cbar = plt.colorbar(scatter, ax=axes[0, 1])\n",
        "    cbar.set_label('Total de Eventos')\n",
        "\n",
        "# Gr√°fico 3: Clusters de usu√°rios\n",
        "if comportamento_df is not None and 'cluster' in comportamento_df.columns:\n",
        "    cluster_colors = {0: 'lightcoral', 1: 'gold', 2: 'lightgreen'}\n",
        "    cluster_labels = {0: 'Passivos', 1: 'Ativos Baixa Conv.', 2: 'Ativos Convertidos'}\n",
        "    \n",
        "    for cluster_id in range(3):\n",
        "        cluster_data = comportamento_df[comportamento_df['cluster'] == cluster_id]\n",
        "        axes[0, 2].scatter(cluster_data['total_eventos'], cluster_data['taxa_conversao'],\n",
        "                          c=cluster_colors[cluster_id], label=cluster_labels[cluster_id],\n",
        "                          alpha=0.7, s=100, edgecolors='black')\n",
        "    \n",
        "    axes[0, 2].set_title('üéØ Clusters de Usu√°rios', fontweight='bold')\n",
        "    axes[0, 2].set_xlabel('Total de Eventos')\n",
        "    axes[0, 2].set_ylabel('Taxa de Convers√£o')\n",
        "    axes[0, 2].legend()\n",
        "    axes[0, 2].grid(True, alpha=0.3)\n",
        "\n",
        "# Gr√°fico 4: Distribui√ß√£o de valores de compra (PostgreSQL)\n",
        "if usuarios_transacionais is not None and not usuarios_transacionais.empty:\n",
        "    axes[1, 0].hist(usuarios_transacionais['valor_total_compras'], bins=15, alpha=0.7, \n",
        "                   color='lightgreen', edgecolor='black')\n",
        "    axes[1, 0].set_title('üí∞ Distribui√ß√£o de Valores de Compra', fontweight='bold')\n",
        "    axes[1, 0].set_xlabel('Valor Total Compras (R$)')\n",
        "    axes[1, 0].set_ylabel('Frequ√™ncia')\n",
        "    axes[1, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Adicionar estat√≠sticas\n",
        "    mean_value = usuarios_transacionais['valor_total_compras'].mean()\n",
        "    axes[1, 0].axvline(mean_value, color='red', linestyle='--', linewidth=2, label=f'M√©dia: R$ {mean_value:,.0f}')\n",
        "    axes[1, 0].legend()\n",
        "\n",
        "# Gr√°fico 5: Segmentos de usu√°rios\n",
        "if usuarios_transacionais is not None and not usuarios_transacionais.empty:\n",
        "    segmentos = usuarios_transacionais['segmento'].value_counts()\n",
        "    colors = ['gold', 'lightblue', 'lightcoral', 'lightgreen']\n",
        "    wedges, texts, autotexts = axes[1, 1].pie(segmentos.values, labels=segmentos.index, \n",
        "                                            autopct='%1.1f%%', startangle=90, colors=colors)\n",
        "    axes[1, 1].set_title('üë• Distribui√ß√£o por Segmento', fontweight='bold')\n",
        "    \n",
        "    # Melhorar legibilidade\n",
        "    for autotext in autotexts:\n",
        "        autotext.set_color('white')\n",
        "        autotext.set_fontweight('bold')\n",
        "\n",
        "# Gr√°fico 6: Probabilidade de churn\n",
        "if usuarios_transacionais is not None and 'probabilidade_churn' in usuarios_transacionais.columns:\n",
        "    # Criar bins para probabilidade de churn\n",
        "    bins = [0, 0.3, 0.7, 1.0]\n",
        "    labels = ['Baixo Risco', 'M√©dio Risco', 'Alto Risco']\n",
        "    usuarios_transacionais['risco_churn'] = pd.cut(usuarios_transacionais['probabilidade_churn'], \n",
        "                                                  bins=bins, labels=labels, include_lowest=True)\n",
        "    \n",
        "    risco_counts = usuarios_transacionais['risco_churn'].value_counts()\n",
        "    colors = ['lightgreen', 'gold', 'lightcoral']\n",
        "    \n",
        "    bars = axes[1, 2].bar(risco_counts.index, risco_counts.values, color=colors, alpha=0.7, edgecolor='black')\n",
        "    axes[1, 2].set_title('üö® Distribui√ß√£o de Risco de Churn', fontweight='bold')\n",
        "    axes[1, 2].set_ylabel('N√∫mero de Usu√°rios')\n",
        "    axes[1, 2].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Adicionar valores nas barras\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        axes[1, 2].text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
        "                       f'{int(height)}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "# Ajustar layout\n",
        "plt.tight_layout()\n",
        "\n",
        "# Salvar gr√°fico\n",
        "plt.savefig('dashboard_analise_preditiva.png', dpi=300, bbox_inches='tight')\n",
        "print(\"‚úÖ Dashboard salvo como 'dashboard_analise_preditiva.png'\")\n",
        "\n",
        "# Mostrar gr√°fico\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüéâ Visualiza√ß√µes criadas com sucesso!\")\n",
        "print(\"üìä Dashboard completo com an√°lises de MongoDB e PostgreSQL\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Parte 6: Sistema de Recomenda√ß√µes\n",
        "\n",
        "### Objetivo: Gerar recomenda√ß√µes personalizadas baseadas na an√°lise preditiva\n",
        "\n",
        "Vamos implementar:\n",
        "1. **Algoritmo colaborativo simples**\n",
        "2. **Scoring baseado em comportamento**\n",
        "3. **Recomenda√ß√µes por cluster**\n",
        "4. **Integra√ß√£o MongoDB + PostgreSQL**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üéØ Sistema de Recomenda√ß√µes\n",
        "print(\"üéØ Gerando recomenda√ß√µes personalizadas...\")\n",
        "\n",
        "def gerar_recomendacoes(usuario_id, comportamento_df, usuarios_transacionais):\n",
        "    \"\"\"Gerar recomenda√ß√µes para um usu√°rio espec√≠fico\"\"\"\n",
        "    \n",
        "    # Produtos dispon√≠veis (simulados)\n",
        "    produtos_disponiveis = [\n",
        "        {'id': 'P001', 'nome': 'Smartphone Galaxy S24', 'categoria': 'smartphones', 'preco': 2999.99},\n",
        "        {'id': 'P002', 'nome': 'iPhone 15 Pro', 'categoria': 'smartphones', 'preco': 8999.99},\n",
        "        {'id': 'P003', 'nome': 'Notebook Dell XPS 13', 'categoria': 'notebooks', 'preco': 5999.99},\n",
        "        {'id': 'P004', 'nome': 'Tablet iPad Air', 'categoria': 'tablets', 'preco': 3999.99},\n",
        "        {'id': 'P005', 'nome': 'Smartphone Xiaomi 13', 'categoria': 'smartphones', 'preco': 1999.99},\n",
        "        {'id': 'P006', 'nome': 'Notebook MacBook Air', 'categoria': 'notebooks', 'preco': 7999.99},\n",
        "        {'id': 'P007', 'nome': 'Tablet Samsung Galaxy Tab', 'categoria': 'tablets', 'preco': 2499.99},\n",
        "        {'id': 'P008', 'nome': 'Smartphone Pixel 8', 'categoria': 'smartphones', 'preco': 3499.99}\n",
        "    ]\n",
        "    \n",
        "    # Buscar dados do usu√°rio\n",
        "    user_comportamento = comportamento_df[comportamento_df['usuario_id'] == usuario_id] if comportamento_df is not None else None\n",
        "    user_transacional = usuarios_transacionais[usuarios_transacionais['usuario_id'] == usuario_id] if usuarios_transacionais is not None else None\n",
        "    \n",
        "    recomendacoes = []\n",
        "    \n",
        "    for produto in produtos_disponiveis:\n",
        "        score = 0.0\n",
        "        motivos = []\n",
        "        \n",
        "        # Score baseado em comportamento (MongoDB)\n",
        "        if user_comportamento is not None and not user_comportamento.empty:\n",
        "            user_data = user_comportamento.iloc[0]\n",
        "            \n",
        "            # Usu√°rios ativos t√™m prefer√™ncia por produtos similares\n",
        "            if user_data['total_eventos'] > comportamento_df['total_eventos'].mean():\n",
        "                score += 0.3\n",
        "                motivos.append(\"usu√°rio_ativo\")\n",
        "            \n",
        "            # Usu√°rios com alta convers√£o preferem produtos premium\n",
        "            if user_data['taxa_conversao'] > comportamento_df['taxa_conversao'].mean():\n",
        "                if produto['preco'] > 5000:\n",
        "                    score += 0.2\n",
        "                    motivos.append(\"preferencia_premium\")\n",
        "                else:\n",
        "                    score += 0.1\n",
        "                    motivos.append(\"produto_acessivel\")\n",
        "            \n",
        "            # Usu√°rios que visualizam muitos produtos t√™m prefer√™ncia diversificada\n",
        "            if user_data['produtos_unicos'] > comportamento_df['produtos_unicos'].mean():\n",
        "                score += 0.15\n",
        "                motivos.append(\"interesse_diversificado\")\n",
        "        \n",
        "        # Score baseado em dados transacionais (PostgreSQL)\n",
        "        if user_transacional is not None and not user_transacional.empty:\n",
        "            user_data = user_transacional.iloc[0]\n",
        "            \n",
        "            # Usu√°rios high_value preferem produtos caros\n",
        "            if user_data['segmento'] == 'high_value':\n",
        "                if produto['preco'] > 5000:\n",
        "                    score += 0.4\n",
        "                    motivos.append(\"segmento_high_value\")\n",
        "                else:\n",
        "                    score += 0.1\n",
        "                    motivos.append(\"produto_economico\")\n",
        "            \n",
        "            # Usu√°rios com muitos pedidos preferem produtos populares\n",
        "            if user_data['total_pedidos'] > usuarios_transacionais['total_pedidos'].mean():\n",
        "                score += 0.2\n",
        "                motivos.append(\"cliente_frequente\")\n",
        "            \n",
        "            # Usu√°rios com baixo risco de churn t√™m prefer√™ncia por produtos similares\n",
        "            if 'probabilidade_churn' in user_data and user_data['probabilidade_churn'] < 0.3:\n",
        "                score += 0.15\n",
        "                motivos.append(\"baixo_risco_churn\")\n",
        "        \n",
        "        # Score baseado em cluster (se dispon√≠vel)\n",
        "        if user_comportamento is not None and 'cluster' in user_comportamento.columns:\n",
        "            cluster = user_comportamento.iloc[0]['cluster']\n",
        "            \n",
        "            if cluster == 2:  # Usu√°rios ativos e convertidos\n",
        "                score += 0.25\n",
        "                motivos.append(\"cluster_ativo_convertido\")\n",
        "            elif cluster == 1:  # Usu√°rios ativos mas baixa convers√£o\n",
        "                if produto['preco'] < 3000:  # Produtos mais baratos\n",
        "                    score += 0.2\n",
        "                    motivos.append(\"cluster_ativo_baixa_conv\")\n",
        "            elif cluster == 0:  # Usu√°rios passivos\n",
        "                if produto['preco'] < 2000:  # Produtos muito baratos\n",
        "                    score += 0.15\n",
        "                    motivos.append(\"cluster_passivo\")\n",
        "        \n",
        "        # Adicionar score baseado em categoria (simula√ß√£o de prefer√™ncia)\n",
        "        categoria_scores = {'smartphones': 0.1, 'notebooks': 0.05, 'tablets': 0.08}\n",
        "        score += categoria_scores.get(produto['categoria'], 0.02)\n",
        "        \n",
        "        # Adicionar ru√≠do aleat√≥rio para simular varia√ß√£o\n",
        "        score += random.uniform(-0.1, 0.1)\n",
        "        score = max(0, min(1, score))  # Manter entre 0 e 1\n",
        "        \n",
        "        recomendacoes.append({\n",
        "            'produto_id': produto['id'],\n",
        "            'nome': produto['nome'],\n",
        "            'categoria': produto['categoria'],\n",
        "            'preco': produto['preco'],\n",
        "            'score': score,\n",
        "            'motivos': motivos\n",
        "        })\n",
        "    \n",
        "    # Ordenar por score e retornar top 5\n",
        "    recomendacoes.sort(key=lambda x: x['score'], reverse=True)\n",
        "    return recomendacoes[:5]\n",
        "\n",
        "# Gerar recomenda√ß√µes para alguns usu√°rios\n",
        "usuarios_exemplo = ['U001', 'U002', 'U003', 'U004', 'U005']\n",
        "\n",
        "print(\"üéØ Recomenda√ß√µes Personalizadas:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for usuario in usuarios_exemplo:\n",
        "    print(f\"\\nüë§ Usu√°rio: {usuario}\")\n",
        "    \n",
        "    # Buscar informa√ß√µes do usu√°rio\n",
        "    user_info = \"\"\n",
        "    if comportamento_df is not None:\n",
        "        user_comp = comportamento_df[comportamento_df['usuario_id'] == usuario]\n",
        "        if not user_comp.empty:\n",
        "            user_info += f\"Eventos: {user_comp.iloc[0]['total_eventos']}, \"\n",
        "            user_info += f\"Convers√£o: {user_comp.iloc[0]['taxa_conversao']:.1%}\"\n",
        "            if 'cluster' in user_comp.columns:\n",
        "                cluster_names = {0: 'Passivo', 1: 'Ativo Baixa Conv.', 2: 'Ativo Convertido'}\n",
        "                user_info += f\", Cluster: {cluster_names.get(user_comp.iloc[0]['cluster'], 'N/A')}\"\n",
        "    \n",
        "    if usuarios_transacionais is not None:\n",
        "        user_trans = usuarios_transacionais[usuarios_transacionais['usuario_id'] == usuario]\n",
        "        if not user_trans.empty:\n",
        "            user_info += f\", Segmento: {user_trans.iloc[0]['segmento']}\"\n",
        "            if 'probabilidade_churn' in user_trans.columns:\n",
        "                user_info += f\", Risco Churn: {user_trans.iloc[0]['probabilidade_churn']:.1%}\"\n",
        "    \n",
        "    print(f\"üìä Perfil: {user_info}\")\n",
        "    \n",
        "    # Gerar recomenda√ß√µes\n",
        "    recomendacoes = gerar_recomendacoes(usuario, comportamento_df, usuarios_transacionais)\n",
        "    \n",
        "    print(\"üéØ Top 3 Recomenda√ß√µes:\")\n",
        "    for i, rec in enumerate(recomendacoes[:3], 1):\n",
        "        print(f\"  {i}. {rec['nome']}\")\n",
        "        print(f\"     Pre√ßo: R$ {rec['preco']:,.2f}\")\n",
        "        print(f\"     Score: {rec['score']:.2f}\")\n",
        "        print(f\"     Motivos: {', '.join(rec['motivos'])}\")\n",
        "        print()\n",
        "\n",
        "print(\"‚úÖ Sistema de recomenda√ß√µes implementado com sucesso!\")\n",
        "print(\"üéØ Recomenda√ß√µes baseadas em an√°lise preditiva de MongoDB + PostgreSQL\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
